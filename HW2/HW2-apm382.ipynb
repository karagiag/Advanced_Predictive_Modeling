{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: Advanced Predictive Modeling</p>\n",
    "# <p style=\"text-align: center;\">Assignment 2</p>\n",
    "## <p style=\"text-align: center;\">Total points: 60</p>\n",
    "## <p style=\"text-align: center;\">Due: Wed, October 05, by 11:59pm</p>\n",
    "\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook** (except for Q6). Please submit **only one** ipynb file from each group, and include the names of all the group members in your ipynb file. Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 1: Sampling (6 pts)\n",
    "\n",
    "A recent survey estimated that $30\\%$ of all Europeans aged 20 to 22 have driven under the influence of drugs or alcohol, based on a simple \"Yes or No\" question. A similar survey is being planned for Americans. The survey designers want the  $90\\%$ confidence interval to have a margin of error of at most $\\pm0.09$.\n",
    "\n",
    "(a) Find the necessary sample size needed to conduct this survey assuming that the expected percentage of \"yes\" answers will be very close to that obtained from the European survey? (2 pts)\n",
    "\n",
    "(b) Suppose the tolerance level was kept the same but the confidence level needs to increase to $95\\%$. What is the required sample size for this new specification? (2 pts)\n",
    "\n",
    "(c) If one does not know where the true \"$p$\" may lie, one can conservatively conduct a survey assuming the worst case (in terms of required minimum sample size)  scenario of  $p = 0.5$. Redo part (b) for this \"worst case\" scenario. (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (2+2 = 4 points)\n",
    "\n",
    "View the video at:\n",
    "\n",
    "https://www.youtube.com/watch?v=jbkSRLYSojo\n",
    "\n",
    "(Hans Rosling's 200 Countries, 200 Years, 4 Minutes) and answer the following questions:\n",
    "\n",
    "1. How many variables are being visualized in the “moving bubble plots” video (list them)?\n",
    "\n",
    "2. Identify a variable that is “zoomed into”, i.e., examined at a sub-category or more detailed level.\n",
    "\n",
    "\n",
    "FACTOID: Rosling’s gapminder visualization\n",
    "\n",
    "(see https://www.youtube.com/user/Gapcast for some more insightful videos) can now be\n",
    "\n",
    "readily used by you via Google Charts: https://developers.google.com/chart/interactive/docs/gallery\n",
    "\n",
    "Just plug in your own variables into “Bubble Chart” under the URL above and go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Principal Component Analysis (PCA) (10 pts)\n",
    "\n",
    "Download the US imports dataset from Canvas, or from [here](https://www.census.gov/foreign-trade/statistics/product/enduse/imports/enduse_imports.xlsx).\n",
    "\n",
    "This code will clean the data and format it so that it is PCA-ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated countries: \n",
      "['Montenegro', 'Serbia', 'Sudan']\n",
      "countries that don't trade with USA: \n",
      "['Cuba', 'Korea, North', 'Netherlands Antilles']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('enduse_imports.xlsx')\n",
    "\n",
    "# gather columns we care about\n",
    "df = df.loc[:,['CTY_DESC','COMM_DESC','value_15']]\n",
    "df.columns = pd.Series(['Country','Good','Value'])\n",
    "\n",
    "# not a country, remove\n",
    "df = df[df['Country'] != 'World Total']\n",
    "\n",
    "# some countries had imports recorded twice\n",
    "# remove these countries for simplicity\n",
    "importCount = df.groupby(['Country','Good']).count().iloc[:,0]\n",
    "duplicatedImports = importCount[importCount > 1]\n",
    "countriesWithDuplicates = duplicatedImports.index.get_level_values(0).unique()\n",
    "print \"duplicated countries: \"\n",
    "print [str(country) for country in countriesWithDuplicates]\n",
    "df = df[df['Country'].isin(countriesWithDuplicates) == False]\n",
    "\n",
    "# remove countries that don't export\n",
    "totalImports = df[['Country','Value']].groupby('Country').sum().iloc[:,0]\n",
    "countriesWithNoImport = totalImports[totalImports == 0].index\n",
    "print \"countries that don't trade with USA: \"\n",
    "print [str(country) for country in countriesWithNoImport]\n",
    "df = df[df['Country'].isin(countriesWithNoImport) == False]\n",
    "\n",
    "# reshape so that each type of good has its own column\n",
    "df = df.pivot(index='Country',columns='Good',values='Value')\n",
    "df = df.fillna(0)\n",
    "\n",
    "# import PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Good</th>\n",
       "      <th>Agricultural machinery, equipment</th>\n",
       "      <th>Alcoholic beverages, excluding wine</th>\n",
       "      <th>Apparel, household goods - cotton</th>\n",
       "      <th>Apparel, household goods - wool</th>\n",
       "      <th>Apparel, textiles, nonwool or cotton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>3105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10739.0</td>\n",
       "      <td>7314.0</td>\n",
       "      <td>11942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34741.0</td>\n",
       "      <td>2752171.0</td>\n",
       "      <td>50838.0</td>\n",
       "      <td>1298224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Good         Agricultural machinery, equipment  \\\n",
       "Country                                          \n",
       "Afghanistan                             3105.0   \n",
       "Albania                                    0.0   \n",
       "Algeria                                    0.0   \n",
       "Andorra                                    0.0   \n",
       "Angola                                     0.0   \n",
       "\n",
       "Good         Alcoholic beverages, excluding wine  \\\n",
       "Country                                            \n",
       "Afghanistan                                  0.0   \n",
       "Albania                                  34741.0   \n",
       "Algeria                                      0.0   \n",
       "Andorra                                      0.0   \n",
       "Angola                                   24505.0   \n",
       "\n",
       "Good         Apparel, household goods - cotton  \\\n",
       "Country                                          \n",
       "Afghanistan                            10739.0   \n",
       "Albania                              2752171.0   \n",
       "Algeria                                    0.0   \n",
       "Andorra                                  351.0   \n",
       "Angola                                     0.0   \n",
       "\n",
       "Good         Apparel, household goods - wool  \\\n",
       "Country                                        \n",
       "Afghanistan                           7314.0   \n",
       "Albania                              50838.0   \n",
       "Algeria                                  0.0   \n",
       "Andorra                                  0.0   \n",
       "Angola                                   0.0   \n",
       "\n",
       "Good         Apparel, textiles, nonwool or cotton  \n",
       "Country                                            \n",
       "Afghanistan                               11942.0  \n",
       "Albania                                 1298224.0  \n",
       "Algeria                                       0.0  \n",
       "Andorra                                       0.0  \n",
       "Angola                                        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5,:5] # display first five rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now gather the top two principal components from this dataset and  \n",
    "(a) Make a scatter plot with the first component as the x-axis and the second as the y-axis. (3 pts)\n",
    "\n",
    "(b) Find the names of the six countries with the highest first component (these should be clear outliers). (2 pts)\n",
    "\n",
    "(c) Given the results of parts (a) and (b), one might theorize that the first component roughly represents the total volume of exports to the US.  Using the components\\_ attribute, gather the loadings of the first component.  Also use the original dataframe to gather the total imports to the US for each good.  Divide this list of total imports per good by the total US imports period, so that for each good we know what percent of imports it accounted for.  Make a scatter plot with this value on the x-axis and the first component's loadings on the right. (3 pts)\n",
    "\n",
    "(d) For the four goods with the highest component loadings, print the name of the good and the percent of imports it accounts for.  Briefly comment on whether you think the first component represents the total volume of imports, or whether it has another interpretation - no right or wrong answer. (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Visualization using Bokeh (10 pts)\n",
    "\n",
    "In this problem, you'll build an interactive visualization. Bokeh is a Python interactive visualization library that targets modern web browsers for presentation. For more information on Bokeh, see http://bokeh.pydata.org/en/latest/. The problem statement is as follows:\n",
    "\n",
    "Using the [King County House Sales](http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original) data, your goal is to build a Bokeh visualization which allows the user explore how price varies with living room size and year built. You will create a visualization that allows the user to toggle the X axis of a scatter plot between living room size and year built, with the y-axis always being price. Also add the hover tool so that if the user hovers over a datapoint in the living-room-size plot a window pops up that shows year built - and vice versa.\n",
    "\n",
    "Hints: \n",
    "1. You can make use of Select widgets.\n",
    "2. See: http://bokeh.pydata.org/en/latest/docs/user_guide/interaction.html#javascript-callbacks. Specifically look at the CustomJS for Widgets under Callbacks and the Select widget. \n",
    "3. see: http://bokeh.pydata.org/en/latest/docs/user_guide/tools.html#basic-tooltips for a hover tool example.\n",
    "4. See: http://bokeh.pydata.org/en/latest/docs/reference/plotting.html. Look for the scatter API.\n",
    "5. See: http://bokeh.pydata.org/en/0.10.0/docs/user_guide/styling.html#labels. For labeling axes.\n",
    "6. Use output_notebook() from Bokeh to output the plot to your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 5: Ridge and Lasso Regression (6+6+4+4=20 points)\n",
    "\n",
    "In this question, you will explore the application of Lasso and Ridge regression using sklearn package in Python. The dataset is Hitters.csv (available on canvas), which contains performance records and salaries for baseball players. More information on the data can be found [here](https://rdrr.io/cran/ISLR/man/Hitters.html). There are 17 variables: first 16 columns are performance related features and the last column is for Salary. We\n",
    "wish to predict a baseball player’s Salary using all the 16 performance variables. Use a random state of 42 and a test size of 1/3 to [split the data into training and test](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html). Note: lambda is called alpha in sklearn.\n",
    "\n",
    "1. Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can consider this range of values as follows:\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    alphas =  10\\***np.linspace(10,-2,100)*\\*0.5\n",
    "\n",
    "    Report the best chosen $\\lambda$ based on cross validation. The cross validation should happen on your training data using  average MSE as the scoring metric.\n",
    "2. Run ridge and lasso for all of the parameters specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; the plots for different features for a method should be on the same plot (e.g. Fig 6.6 of JW). What do you qualitatively observe when value of the regularization parameter is changed? \n",
    "3. Run least squares regression, ridge, and lasso on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MSE) on the test data for each.\n",
    "4. Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "    Report the best $\\lambda$ based on cross validation. Run lasso on the training data using the best $\\lambda$ and report the coefficeints for 16 variables. What do you observe from these coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Shiny app using R (10 points)\n",
    "\n",
    "In this problem, you'll build a Shiny application. Shiny is an R\n",
    "package which lets you publish web applications from R easily. For\n",
    "more information on Shiny, see http://shiny.rstudio.com. The problem\n",
    "statement is as follows:\n",
    "\n",
    "We are going to use the \"WorldPhones\" dataset available in\n",
    "\"datasets\" package. This dataset shows the number of\n",
    "telephones (in thousands) in various regions of the world in\n",
    "different years. The dataset will be loaded into a variable named\n",
    "\"WorldPhones\" once you include the datasets\n",
    "package (library(datasets)). Your goal is to build a Shiny\n",
    "app which allows the user to visualize the distribution of the\n",
    "number of telephones by region and by year (using bar graph). The\n",
    "requirements are as follows:\n",
    "\n",
    "\n",
    "1. You will give the user the option to choose between \"Region\" and\n",
    "\"Year\". Use [check-box](http://shiny.rstudio.com/reference/shiny/latest/checkboxGroupInput.html) to get the user option. The default\n",
    "option should be \"Region\".\n",
    "2. You will also give the user the ability to choose between different regions and years. (Hint: You can make use of drop-down lists)\n",
    "3. Plot a bargraph of the feature chosen by the user. For example, if the user\n",
    "selects \"Region\" using the check-box, and then selects\n",
    "\"Asia\" from the drop-down list of \"Region\",\n",
    "you need to plot a bar graph showing the number of telephones in\n",
    "Asia in various years. Similarly, if the user selects\n",
    "\"Year\" using the check-box, and then selects\n",
    "\"1951\" from the drop-down list of \"Year\", you\n",
    "need to plot a bar graph showing the number of telephones in 1951 in\n",
    "various regions. Note that if the user selects both Region and Year\n",
    "(using the check-boxes), the app will work as if only the Region has\n",
    "been selected.\n",
    "\n",
    "\n",
    "We have made available sample screenshots of our Shiny app that\n",
    "supports the above requirements, namely $shiny1.png$ and\n",
    "$shiny2.png$ (available on canvas). Your interface should look\n",
    "similar to the screenshots.\n",
    "\n",
    "\n",
    "The tutorials listed below should provide you the needed background\n",
    "to solve this problem:\n",
    "\n",
    "1. http://shiny.rstudio.com/tutorial/lesson1\n",
    "2. http://shiny.rstudio.com/gallery/\n",
    "3. http://shiny.rstudio.com/reference/shiny/latest/checkboxGroupInput.html\n",
    "\n",
    "You can submit the code and results via a PDF or other format. Just please make a reference to it in your notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
